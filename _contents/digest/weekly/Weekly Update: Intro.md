

## 5점

### 1. Model context protocol (MCP)

(요약) AI 봇, 에이전트들 간의 interface에 대한 표준을 제안함. *인간을 위한 html css, code/bot을 위한 json api graphql grpc, AI/LLM bot을 위한 interface 표준: ???*

> **Why it matters:**
해당 proposal 중 가장 novel함. 필요성이 크고, 성공적으로 ecosystem을 구축한다면 잠재적으로 매우 중요함.
> 

## 4점

### 1. 에이전트 내 자연어 검색 품질 향상 기법 : Entity RAG, Knowledge-aware retrieval

자연어 검색은 LLM 기술을 활용해 사용자의 질의를 문맥과 의도에 맞게 분석, 최적의 결과를 제공하는 기술임.  Entity RAG는 LLM의 최신 데이터 부족 문제를 보완하기 위해 경량검색으로 추출된 정보를 프롬프트에 삽입하여 개체 인식 정확도를 높임. Knowledge-aware retrieval은 사용자와 에이전트가 이해하는 키워드 및 테마 간 차이를 시맨틱 검색을 통해 연결, 적절한 검색결과를 반환함. 두 기법 모두 기존 키워드 검색의 한계를 극복하며, 복잡하거나 모호한 질의에 대해 더 정확한 결과 제공에 기여함. 향후 미디어, 뮤직 등 다양한 도메인에 적용 확대 및 개인화, 멀티모달 기술과 융합하여 검색추천 경험을 더욱 개선할 계획.

> **Why it matters:
- 최신 데이터 인식 보완:** Entity RAG 기법을 통해 LLM이 최신 데이터를 효과적으로 인식할 수 있어, 실제 서비스 환경에서 발생하는 최신 이슈나 신규 개체에 대해 보다 정확한 응답을 제공
**- 의도 및 개체 인식 개선:** 사용자 질의의 문맥과 의도를 정교하게 분석하여 검색 결과의 품질을 높이는 기술은 LLM을 활용하는 모든 분야에서 핵심적인 역할을 함
**- 다양한 도메인 적용 가능성:** 미디어, 뮤직, 증권 등 다양한 분야에 적용할 수 있으며, 특히 복잡하거나 모호한 질의에 대해 기존 방식보다 개선된 결과를 도출할 수 있음
**- 시맨틱 검색과의 융합:** Knowledge-aware retrieval을 통해 사용자가 이해하는 키워드와 시스템 내부의 데이터 체계 간의 차이를 극복, 의미 기반 검색을 효과적으로 지원
> 

## 3점

### 1. **MoA(Mixture-of-Agents, 에이전트 혼합 기법)**

MoA(Mixture-of-Agents)는 LLM 자체를 변경하지 않고 프롬프트와 sampling options(예: temperature)만 조정하여 성능을 개선하는 기법이다. 여러 LLM 에이전트를 계층적으로 구성하며, 이전 계층의 출력을 기반으로 점진적으로 응답을 발전시킨다. 각 계층에는 제안자(Proposer)와 집계자(Aggregator)가 존재하며, 제안자는 초기 응답을 생성하고 집계자는 이를 종합하여 개선된 응답을 반환한다. 이러한 반복적 개선 과정을 통해 보다 정교한 최종 출력을 생성할 수 있다. MoA는 다양한 모델을 활용하여 협업적이고 효율적인 AI 응답 생성을 목표로 한다.

> **Why it matters:
1. 단일 LLM의 한계를 극복**
여러 개의 LLM을 계층적으로 조합하여 개별 모델이 가진 약점을 보완하고, 더 정교한 응답을 생성
2. **프롬프트 엔지니어링만으로 성능 향상 가능**
모델 자체를 변경하거나 추가적인 fine-tuning 없이, 프롬프트와 샘플링 옵션(예: temperature)을 조정하는 방식으로 성능을 향상
**모델 훈련 없이도 성능을 개선**할 수 있다는 장점이 있지만 여러 LLM을 계층적으로 사용하기에 발생하는 latency가 불가피할 것으로 보임
> 

### 2. Agentic Document Extraction

**Agentic 문서 추출 기술**은 문서에서 정보를 추출하는 새로운 방식입니다. 기존의 OCR 기반 방법이나 텍스트 변환(text2text) 방식과 달리, 이 기술은 텍스트뿐만 아니라 체크박스, 그래프, 차트, 다이어그램, 표와 같은 시각적 요소까지 분석하여 문서의 의미를 포착합니다. 예를 들어, 흐름도에서 요소 간의 연결 관계를 이해하거나 차트에서 정보를 추출하는 데 유용합니다. 또한, 문서 내 구성 요소를 활용해 논리적으로 해석함으로써 독자가 저자가 전달하려는 내용을 더 쉽게 이해할 수 있도록 돕습니다.

> **Why it matters:**
오늘날의 문서는 단순한 텍스트뿐만 아니라 다양한 시각적 요소를 포함하고 있으며, 이러한 시각적 요소에는 중요한 데이터가 많이 담겨 있습니다. 그러나 기존 방식으로는 시각적 요소를 배제한 채 정보를 추출하기 때문에 불완전한 데이터 수집이 발생할 수 있습니다. Agentic 문서 추출 기술을 활용하면 보다 정확한 데이터 추출이 가능하며, 나아가 독자의 이해도를 평가하는 데에도 활용할 수 있습니다.
> 

## 2점

### 1.Why can’t ChatGPT Draw full glass of wine?

GPT는 실존하지 않는 유니콘을 그려냈지만 실존하는 가득찬 와인잔을 그려내지못했다.
해당 영상은 경험주의 철학을 기반으로, 상상가능한것과 불가능한 것을 구분한다.
GPT가 연속되는 색의 빈공간을 채우는 예시를 통해
왜 유니콘은 가능하지만 가득찬 와인잔은 불가능한지 이유를 설명한다.

> **Why it matters:**

’AI의 창의력이 무엇인가?’ 에 대해 가볍게 보기 좋음
> 

## 1점

### 1. **효율적인 벡터 검색 알고리즘 HNSW 알아보기**

HNSW는 ANN(Approximate Nearest Neighbor)을 위한 알고리즘으로, KNN과 다르게 완벽하게 정확하지 않지만 빠른 벡터 검색을 위한 알고리즘입니다HNSW 제외하더라고 Annoy, LSH, Faiss와 같은 다른 ANN 방법론이 존재하지만, HNSW는 실시간 데이터 삽입이 가능하고, 상대적으로 낮은 메모리 사용량을 가지고 있기 때문에 다른 ANN 방법에 비해 범용적으로 사용하기 좋다. HNSW의 원리는 계층적 그래프 구조를 통해 최상위에서 하위로 내려갈 수록 더 많은 노드를 유지하여, 단계적으로 검색을 진행해 빠르게 탐색할 수 있게 한다. 

> Why it matters
> 

RAG를 위해 핵심적인 요소인 Vector database가 사용하는 대표적인 방법들(HNSW, Annoy, LSH, FAISS)의 장단점을 비교하고, 다른 방법과 비교하여 HNSW가 더 적합한 이유와 HNSW의 알고리즘에 대한 개념적인 설명을 하고 있다
